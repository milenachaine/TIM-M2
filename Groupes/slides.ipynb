{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le projet : Chatlaw\n",
    "\n",
    "## Présentation du concept\n",
    "\n",
    "L'objectif de ce projet est de réaliser un chatbot nous permettant d'obtenir une réponse sur une question du domaine juridique. Cette réponse étant obtenu à l'aide d'une similarité d'une réponse déjà présente sur des forums.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Images/schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Etapes du projet\n",
    "## crawling de différents sites pour obtenir des données\n",
    "## prétraitement des données\n",
    "## catégorisation automatique de ces données\n",
    "## interaction avec l'utilisateur\n",
    " - l'utilisateur peut poser une question juridique et reçoit la question la plus similaire à la sienne dans la base de données, ainsi que la réponse associée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Crawling\n",
    "\n",
    "## Objectif et tâches\n",
    "\n",
    "- Crawler plusieurs forums de droit afin de constituer un corpus de questions/réponses\n",
    "- Créer un fichier XML facile à parser et reprenant des infos clé\n",
    "\n",
    "![Crawler logo](Images/web_crawler_logo_2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Forums crawlés\n",
    "\n",
    "- NetIris (plus de 300K questions, 8 catégories)\n",
    "- Juritravail (plus de 150K questions, 27 catégories)\n",
    "\n",
    "![Juritravail](Images/screenshot_juritravail.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corpus et métadonnées\n",
    "\n",
    "- Pour le calcul de similarité : une suite de questions-réponses plain text\n",
    "- Pour la catégorisation : la catégorie de la question telle qu'indiqué sur le site\n",
    "- D'autres métadonnées utiles :\n",
    "\t- un id unique par doc\n",
    "\t- le nom du site\n",
    "\t- le titre de la page\n",
    "\t- l'url de la page\n",
    "\n",
    "![XML](Images/screenshot_corpus_juritravail.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtrage des réponses\n",
    "\n",
    "- Élimination des réponses \"vides\" en filtrant sur la popularité des auteurs\n",
    "\n",
    "![Réponse Juritravail](Images/screenshot_juritravail_reponse.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Technologie utilisée\n",
    "\n",
    "![Logo Python](Images/logo_python.png)\n",
    "![Logo BeautifulSoup](Images/BeautifulSoup.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Statistiques du corpus\n",
    "\n",
    "- NetIris : 41229 questions, 60421 réponses aspirées\n",
    "- Juritravail : 126911 question, 75019 réponses aspirées\n",
    "\n",
    "![Graphique_1](Images/categories_netiris.png)\n",
    "![Graphique_2](Images/categories_juritravail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour\n"
     ]
    }
   ],
   "source": [
    "a = \"Bonjour\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les tâches de prétraitement sont : \n",
    "\n",
    " - lemmatisation \n",
    " - morpho-syntaxe / syntaxe\n",
    " - Entités nommées\n",
    " - Repérage de références juridiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ces prétraitements sont effectué avec plusieurs scripts python sur chaque question et réponse.\n",
    "- La sorite finale est en format Conll, nous avons chaque question et réponse prétraités et étiquités par tree-tagger.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le script xml2conll.py prend en argument le fichier XML généré par le groupe de Crawiling, on récupère l'id, la classe, et la sous-classe de chaque question, on récupère la ou les réponses de cette question. L'attribut id permetrra de faire le lien avec la/les réponses de cette question:\n",
    "![structure.JPG](pic/structure.JPG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En sortie on aura les fichiers  conll de la question et de la réponses (reliés par l'id).\n",
    "Exemple d'une question en fromat conll : \n",
    "\n",
    "![content_conll.JPG](pic/content_conll.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Entité nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Spacy\n",
    "- Nous avons d'abord essayé spacy, mais nous nous sommes rendu comptes que il n'est pas très performant sur le français. Ainsi qu'en terme de complixité, spacy peut être lent avec un grand corpus. \n",
    "\n",
    "\n",
    "# Plyglot\n",
    "\n",
    "- Plyglot est une librairie de NLP multilingue, un peu comme spacy mais plus rapide. \n",
    "\n",
    "- En plus des tâches standards en TAL, (Tokenisation, Part of speech tagging etc) cette librairie permets d'extraire les entité nommées.\n",
    "\n",
    "- Désavantage : On ne peut pas filtrer les fautes d'orthographes; Le temps d'exécution est long.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Partie du résultat:\n",
    "\n",
    "![ents.JPG](pic/ents.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repérage de références juridiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. TF-IDF. Nous avons récolté un corpus journaliste pour faire la contraste avec notre corpus juridique en retirant les mots qui  ont un score tfidf plus haut dans le corpus juridique. Regardez TFIDF.py. Les défauts sont évidentes, d'abord c'est pas facile de trouver les n-grammes juridiques; aussi, le genre et registre de corpus de contraste est très différent, par exemple, puisque le fichier contraste \"contraste\" ici est un corpus journaliste, donc il n'y a pas la forme en deuxième personne, alors qu'on a beaucoup de conjugaison en deuxième personne dans le corpus juridique. Le résultat est stocké dans \"jury.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![TF-IDF.JPG](pic/TF-IDF.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2.  À partir d'un dictionnaire juridique en ligne nous pouvons extraire la liste des termes juridique dans \"termes_juridiques.txt\", le script de téléchargement est \"jury.py\". A l'aide de cette liste nous pouvons récolter les termes juridiques bien propres depuis notre corpus.        Le script est \"extraction.py\", donne le résultat qui dans  \"jury_words.txt\"   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![law_words.JPG](pic/law_words.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Catégorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interaction avec l'utilisateur\n",
    "## interface graphique\n",
    "\n",
    "![](Images/flask.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## recherche de similarités\n",
    "\n",
    "La recherche de similarité est effectué avec un script en python. \n",
    "Deux scripts sont utilisés pour cela : \n",
    "\n",
    "![](Images/scikit.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### preprocessdocs.py \n",
    "\n",
    "Ce script nous permet de créer un dictionnaire à partir du corpus avec comme attribut, l'id, la classe, la sous-classe, la question, les réponses associées à la question ainsi que la question et les réponses lemmatisées. \n",
    "Le tout est sauvegardé dans des \"pickles\" qui nous permettent de conserver les résultats dans un script python pour pouvoir les réutiliser facilement. Cela nous permet de garder en mémoire celui-ci afin de ne pas refaire le processus dès que l'utilisateur pose une question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### similarite_with_class.py\n",
    "\n",
    "Ce script charge, dans un premier temps, le résultat obtenu précédemment, à partir notamment des classes catégorisées par le groupe ayant effectué la classification des documents, et transforme ce résultat en un vecteur TF-IDF. Ensuite, on utilise sur celui-ci un calcul de similarité cosinus dans les documents appartenant à la même classe que celle de la question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test diaporama pour la présentation avec Doctrine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commande : jupyter nbconvert slides.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Test        | Tableaux           | Markdown  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| ipsum    | lorem | abc |\n",
    "| lorem      | ipsum      |   def |\n",
    "| ipsum | lorem      |    ghi |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
